# AI Data Operations â€“ Sample Tasks

## ðŸ“– Overview
This project contains sample tasks demonstrating core AI Data Operations skills, including classification, evaluation, annotation, and prompt testing. These examples reflect real workflows used in AI model training, quality review, and guideline-based evaluation.

## ðŸ“‚ Project Structure
- `classification/` â€“ Sentiment, intent, toxicity, and relevance classification samples  
- `evaluation/` â€“ Model comparison and quality evaluation tasks  
- `prompt-testing/` â€“ Prompts for instruction following, safety, hallucination checks, and reasoning  
- `README.md` â€“ Project documentation  

## ðŸ§  Skills Demonstrated
- Text classification  
- Annotation and labeling  
- Model output evaluation  
- Safety and bias assessment  
- Prompt engineering and testing  
- Guideline interpretation  

## ðŸš€ Purpose
This project showcases practical examples of AI data work for roles involving:
- AI evaluation  
- Data annotation  
- Quality review  
- Prompt testing  
- LLM safety and alignment  

## ðŸ“Œ Future Additions
- More classification categories  
- Multi-turn conversation evaluation  
- Guideline-based scoring rubrics  
- Larger annotation datasets  
